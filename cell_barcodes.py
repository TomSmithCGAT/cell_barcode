##############################################################################
#
#   MRC FGU CGAT
#
#   $Id$
#
#   Copyright (C) 2017 Tom Smith
#
#   This program is free software; you can redistribute it and/or
#   modify it under the terms of the GNU General Public License
#   as published by the Free Software Foundation; either version 2
#   of the License, or (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
###############################################################################
"""===========================
Pipeline cell barcode
===========================

:Author: Tom Smith
:Release: $Id$
:Date: |today|
:Tags: Python


Overview
========

This pipeline performs the analysis for the manuscript reporting on
the impact of reference transcriptome choice on quantification accuracy and differnential expression analyses

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.ini` file.
CGATReport report requires a :file:`conf.py` and optionally a
:file:`cgatreport.ini` file (see :ref:`PipelineReporting`).

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_ref_transcriptome_paper.py config

Input files
-----------

None required except the pipeline configuration files.

Requirements
------------

The pipeline requires the results from
:doc:`pipeline_annotations`. Set the configuration variable
:py:data:`annotations_database` and :py:data:`annotations_dir`.

On top of the default CGAT setup, the pipeline requires the following
software to be in the path:

.. Add any additional external requirements such as 3rd party software
   or R modules below:

Requirements:

* samtools >= 1.1

Pipeline output
===============

.. Describe output files of the pipeline here

Glossary
========

.. glossary::


Code
====

"""

# import standard modules
import sys
import os
import sqlite3
import pysam
import time

# import pipeline decorators
from ruffus import *
from ruffus.combinatorics import *

# CGAT code imports
import CGAT.Experiment as E

# CGATPipeline imports
import CGATPipelines.Pipeline as P
import CGATPipelines.PipelineMapping as PipelineMapping

# Import utility function from pipeline module file

# load options from the config file
PARAMS = P.getParameters(
    ["%s/pipeline.ini" % os.path.splitext(__file__)[0],
     "../pipeline.ini",
     "pipeline.ini"])

# add configuration values from associated pipelines
#
# 1. pipeline_annotations: any parameters will be added with the
#    prefix "annotations_". The interface will be updated with
#    "annotations_dir" to point to the absolute path names.
PARAMS.update(P.peekParameters(
    PARAMS["hg_annotations_dir"],
    "pipeline_annotations.py",
    on_error_raise=__name__ == "__main__",
    prefix="hg_annotations_",
    update_interface=True))

PARAMS.update(P.peekParameters(
    PARAMS["mm_annotations_dir"],
    "pipeline_annotations.py",
    on_error_raise=__name__ == "__main__",
    prefix="mmx_annotations_",
    update_interface=True))


# if necessary, update the PARAMS dictionary in any modules file.
# e.g.:
#
# import CGATPipelines.PipelineGeneset as PipelineGeneset
# PipelineGeneset.PARAMS = PARAMS
#
# Note that this is a hack and deprecated, better pass all
# parameters that are needed by a function explicitely.

# -----------------------------------------------
# Utility functions
def connect():
    '''utility function to connect to database.

    Use this method to connect to the pipeline database.
    Additional databases can be attached here as well.

    Returns an sqlite3 database handle.
    '''

    dbh = sqlite3.connect(PARAMS["database_name"])
    statement = '''ATTACH DATABASE '%s' as annotations''' % (
        PARAMS["annotations_database"])
    cc = dbh.cursor()
    cc.execute(statement)
    cc.close()

    return dbh

# ---------------------------------------------------
# Specific pipeline tasks

##############################################################################
#  Download raw data
##############################################################################

@mkdir('raw')
@originate('raw/dropseq_mixed_species.fastq.1.gz')
def downloadDropSeq(outfile):
    ''' Download the DropSeq data'''

    sample_basename = outfile.replace(".fastq.1.gz", "")
    outfile2 = sample_basename + ".fastq.2.gz"
    name2ID = {"mixed_species": "SRR1873277"}

    url_prefix = "ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR187/007/"

    sample_id = name2ID[os.path.basename(sample_basename)]

    statement = '''
    wget %(url_prefix)s/%(sample_id)s/%(sample_id)s_1.fastq.gz -O %(outfile)s; 
    wget %(url_prefix)s/%(sample_id)s/%(sample_id)s_2.fastq.gz -O %(outfile2)s
    '''

    P.run()

@mkdir('raw')
@originate('raw/indrop_es.fastq.1.gz')
def downloadInDrop(outfile):
    ''' Download the InDrop data'''

    sample_basename = outfile.replace(".fastq.1.gz", "")
    outfile2 = sample_basename + ".fastq.2.gz"
    name2ID = {"indrop_es_1": "SRR1784310"}

    url_prefix = "ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR178/000/"

    sample_id = name2ID[os.path.basename(sample_basename)]

    statement = '''
    wget %(url_prefix)s/%(sample_id)s/%(sample_id)s_1.fastq.gz -O %(outfile)s; 
    wget %(url_prefix)s/%(sample_id)s/%(sample_id)s_2.fastq.gz -O %(outfile2)s
    '''

    P.run()


@follows(downloadDropSeq,
         downloadInDrop)
def DownloadData():
    pass


##############################################################################
#  Extract barcodes
##############################################################################

@mkdir("extract")
@transform(downloadDropSeq,
           regex("raw/(\S+).fastq.1.gz"),
           r"extract/\1_whitelist.tsv")
def MakeDropSeqWhitelist(infile, outfile):
    'make a whitelist of "true" cell barcodes'

    statement = '''
    umi_tools whitelist  --bc-pattern=CCCCCCCCCCCCNNNNNNNN
    --extract-method=string --plot-prefix=test_plots
    -I %(infile)s -L %(outfile)s.log --subset-reads=50000000 > %(outfile)s
    '''

    P.run()

@mkdir("extract")
@transform(downloadDropSeq,
           regex("raw/(\S+).fastq.1.gz"),
           r"extract/\1_whitelist.tsv")
def MakeDropSeqWhitelist(infile, outfile):
    'make a whitelist of "true" cell barcodes'

    statement = '''
    umi_tools whitelist  --bc-pattern=CCCCCCCCCCCCNNNNNNNN
    --extract-method=string --plot-prefix=%(outfile)s
    -I %(infile)s -L %(outfile)s.log --subset-reads=50000000 > %(outfile)s
    '''

    P.run()

@follows(MakeDropSeqWhitelist, MakeInDropWhitelist)
def MakeWhitelists():
    pass
##############################################################################
#  Build mapping index
##############################################################################

@mkdir("extract")
@transform(downloadDropSeq,
           regex("raw/(\S+).fastq.1.gz"),
           r"extract/\1_whitelist.tsv")
def MakeHumanTranscriptome(infile, outfile):
    'make a fasta with human transcripts'

    statement = '''
    umi_tools whitelist  --bc-pattern=CCCCCCCCCCCCNNNNNNNN
    --extract-method=string --plot-prefix=test_plots
    -I %(infile)s -L %(outfile)s.log --subset-reads=50000000 > %(outfile)s
    '''

    P.run()


##############################################################################
# Generic pipeline tasks                                                     #
##############################################################################
@follows(MakeWhitelist)
def full():
    pass


@follows(mkdir("report"))
def build_report():
    '''build report from scratch.

    Any existing report will be overwritten.
    '''

    E.info("starting report build process from scratch")
    P.run_report(clean=True)


@follows(mkdir("report"))
def update_report():
    '''update report.

    This will update a report with any changes inside the report
    document or code. Note that updates to the data will not cause
    relevant sections to be updated. Use the cgatreport-clean utility
    first.
    '''

    E.info("updating report")
    P.run_report(clean=False)


@follows(update_report)
def publish_report():
    '''publish report in the CGAT downloads directory.'''

    E.info("publishing report")
    P.publish_report()

if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
